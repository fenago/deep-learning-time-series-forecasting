{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# lstm model for the har dataset\n", 
        "from numpy import mean\n", 
        "from numpy import std\n", 
        "from numpy import dstack\n", 
        "from pandas import read_csv\n", 
        "import warnings\n", 
        "warnings.simplefilter(\"ignore\")\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "import tensorflow.python.util.deprecation as deprecation\n", 
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers import LSTM\n", 
        "from keras.utils import to_categorical\n", 
        "\n", 
        "# load a single file as a numpy array\n", 
        "def load_file(filepath):\n", 
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n", 
        "\treturn dataframe.values\n", 
        "\n", 
        "# load a list of files and return as a 3d numpy array\n", 
        "def load_group(filenames, prefix=''):\n", 
        "\tloaded = list()\n", 
        "\tfor name in filenames:\n", 
        "\t\tdata = load_file(prefix + name)\n", 
        "\t\tloaded.append(data)\n", 
        "\t# stack group so that features are the 3rd dimension\n", 
        "\tloaded = dstack(loaded)\n", 
        "\treturn loaded\n", 
        "\n", 
        "# load a dataset group, such as train or test\n", 
        "def load_dataset_group(group, prefix=''):\n", 
        "\tfilepath = prefix + group + '/Inertial Signals/'\n", 
        "\t# load all 9 files as a single array\n", 
        "\tfilenames = list()\n", 
        "\t# total acceleration\n", 
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n", 
        "\t# body acceleration\n", 
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n", 
        "\t# body gyroscope\n", 
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n", 
        "\t# load input data\n", 
        "\tX = load_group(filenames, filepath)\n", 
        "\t# load class output\n", 
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n", 
        "\treturn X, y\n", 
        "\n", 
        "# load the dataset, returns train and test X and y elements\n", 
        "def load_dataset(prefix=''):\n", 
        "\t# load all train\n", 
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n", 
        "\t# load all test\n", 
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n", 
        "\t# zero-offset class values\n", 
        "\ttrainy = trainy - 1\n", 
        "\ttesty = testy - 1\n", 
        "\t# one hot encode y\n", 
        "\ttrainy = to_categorical(trainy)\n", 
        "\ttesty = to_categorical(testy)\n", 
        "\treturn trainX, trainy, testX, testy\n", 
        "\n", 
        "# fit and evaluate a model\n", 
        "def evaluate_model(trainX, trainy, testX, testy):\n", 
        "\tverbose, epochs, batch_size = 0, 15, 64\n", 
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n", 
        "\tmodel = Sequential()\n", 
        "\tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n", 
        "\tmodel.add(Dropout(0.5))\n", 
        "\tmodel.add(Dense(100, activation='relu'))\n", 
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n", 
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", 
        "\t# fit network\n", 
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n", 
        "\t# evaluate model\n", 
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n", 
        "\treturn accuracy\n", 
        "\n", 
        "# summarize scores\n", 
        "def summarize_results(scores):\n", 
        "\tprint(scores)\n", 
        "\tm, s = mean(scores), std(scores)\n", 
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n", 
        "\n", 
        "# run an experiment\n", 
        "def run_experiment(repeats=3):\n", 
        "\t# load data\n", 
        "\ttrainX, trainy, testX, testy = load_dataset()\n", 
        "\t# repeat experiment\n", 
        "\tscores = list()\n", 
        "\tfor r in range(repeats):\n", 
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n", 
        "\t\tscore = score * 100.0\n", 
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n", 
        "\t\tscores.append(score)\n", 
        "\t# summarize results\n", 
        "\tsummarize_results(scores)\n", 
        "\n", 
        "# run the experiment\n", 
        "run_experiment()"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}